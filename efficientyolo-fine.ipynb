{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Initialize","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\")\n    strategy = tf.distribute.TPUStrategy(tpu)\n    print(\"on TPU\")\nexcept tf.errors.NotFoundError:\n    print(\"not on TPU\")\n    strategy = tf.distribute.MirroredStrategy()\n    \nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow_addons -q\n!pip install -U albumentations -q\n!pip install seaborn -q\n!pip install gdown -q\nimport os\nimport psutil\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\nimport math\nimport gc\nimport shutil\nimport xml.etree.ElementTree as ET\nimport albumentations as A\nimport cv2 as cv\n#import tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow_datasets as tfds\nimport tensorflow_probability as tfp\nfrom tensorflow import keras\nfrom keras import Model\nfrom keras.regularizers import l2\nfrom keras.layers import (\n    Add,\n    Concatenate,\n    Conv2D,\n    SeparableConv2D,\n    DepthwiseConv2D,\n    Input,\n    Lambda,\n    LeakyReLU,\n    MaxPool2D,\n    UpSampling2D,\n    ZeroPadding2D,\n    BatchNormalization)\nfrom keras.losses import (\n    BinaryCrossentropy)\nfrom keras.callbacks import (\n    ModelCheckpoint,\n    CSVLogger)\nprint(tf.__version__)\n\nfrom IPython.display import set_matplotlib_formats\nsns.set(rc={\"figure.dpi\":80, 'savefig.dpi':300})\nsns.set_context('notebook')\nsns.set_style(\"ticks\")\nset_matplotlib_formats('retina')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configs","metadata":{}},{"cell_type":"code","source":"config = {\n    'LABELS': ['W', 'C'],\n    'NUM_classes': 2,\n    'INPUT_shape':  [1024, 1024, 3],\n    'ANCHORS':  tf.constant([\n        [(110.69006964, 115.58234666), (150.43162309, 155.19736292)],\n        [(68.92051207, 71.54741845), (85.42938281, 91.21690259)],\n        [(38.6832461, 39.43056285), (53.86257291, 55.85377213)]],\n        tf.float32) / 1300,\n    'ANCHORS_shape': [3, 2],\n    'PARAMS_GS_alpha': [1.5, 1.75, 2.0],\n    'PARAMS_WH_power': [6.0, 4.0, 2.0],\n    'PARAMS_head_scale': [1.0, 1.5, 3.5],\n    'PARAMS_conf_scale': [0.01, 0.01, 0.01],\n    'RES_variations': [1088, 1024, 896, 832, 768, 704, 640]\n}\ndirectory = {\n    'TRAIN_Annotations': '/kaggle/input/w-and-c-hand-signals-arrayfoo/Train/Annotations/',\n    'TRAIN_Images': '/kaggle/input/w-and-c-hand-signals-arrayfoo/Train/Images/',\n    'VALIDATION_Annotations': '/kaggle/input/w-and-c-hand-signals-arrayfoo/Validation/Annotations/',\n    'VALIDATION_Images': '/kaggle/input/w-and-c-hand-signals-arrayfoo/Validation/Images/',\n    'TEST_Annotations': '/kaggle/input/w-and-c-hand-signals-arrayfoo/Test/Annotations/',\n    'TEST_Images': '/kaggle/input/w-and-c-hand-signals-arrayfoo/Test/Images/',\n}\narchitecture = {\n    'backbone': 'EfficientNetV2B1',\n    'SPPF_C': 480,\n    'Neck_C': [120, 240],\n    'Det_Blocks': 2,\n    'Head_Blocks': 1,\n    'Head_C': 128\n}\ncolors = ['#FFA500', '#6A5ACD']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"def XYXY_to_XYWH(box):\n  box_x = (box[0] + box[2]) / 2.0\n  box_y = (box[1] + box[3]) / 2.0\n  box_w = box[2] - box[0]\n  box_h = box[3] - box[1]\n  return tf.stack([[box_x], [box_y], [box_w], [box_h]], axis=-1)\n\ndef XYXY_to_YXYX(x):\n  x1, y1, x2, y2 = tf.split(x[..., :4], (1, 1, 1, 1), axis=-1)\n  return tf.concat([y1, x1, y2, x2], -1)\n\ndef Plot_Bbox_NMS(image, boxes, scores, labels, name=None):\n  fig, ax = plt.subplots(figsize=(16, 12))\n  ax.imshow(tf.squeeze(image))\n  idx_non_zero = tf.where(scores)\n  boxes = tf.gather_nd(boxes, idx_non_zero)\n  scores = tf.gather_nd(scores, idx_non_zero)  \n  labels = tf.gather_nd(labels, idx_non_zero)\n  for box, label in zip(boxes, labels):\n    label = tf.cast(label, tf.int32)\n    box = box[..., :4] * config['INPUT_shape'][0]\n    xywh = XYXY_to_XYWH(box)\n    xywh = tf.squeeze(tf.cast(xywh, tf.int32))\n    box = tf.cast(box, tf.int32)\n    rect = patches.Rectangle((box[0], box[1]), xywh[2], xywh[3], linewidth=2.5, edgecolor=colors[label], facecolor='none')\n    ax.add_patch(rect)\n    ax.text(box[0], box[1] - 8, config['LABELS'][label], fontsize=12, color=colors[tf.squeeze(label)])\n  plt.axis('off');\n  if name:\n    plt.savefig(name)\n    plt.close(fig)\n  else:\n    plt.show()\n\ndef Plot_Bbox(image, labels):\n  fig, ax = plt.subplots(figsize=(16, 12))\n  ax.imshow(tf.squeeze(image))\n  idx_labels = tf.where(labels[..., 4])\n  for label in tf.gather_nd(labels, idx_labels):\n    box = tf.cast(label[..., :4] * config['INPUT_shape'][0], tf.int32).numpy()\n    xywh = XYXY_to_XYWH(box)\n    xywh = tf.squeeze(tf.cast(xywh, tf.int32))\n    idx_class = tf.squeeze(tf.where(label[..., 5:]))\n    rect = patches.Rectangle((box[0], box[1]), xywh[2], xywh[3], linewidth=2.5, edgecolor=colors[idx_class], facecolor='none')\n    ax.add_patch(rect)\n    ax.text(box[0], box[1] - 8, config['LABELS'][idx_class], fontsize=12, color=colors[tf.squeeze(idx_class)])\n  plt.axis('off'); plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class Data_Generator_VOC:\n  def __init__(self, config, directory, ignore_negative=False, mode='TRAIN'):\n    self.output_dim = config['NUM_classes'] + 5\n    self.dir_annot = directory[mode + '_Annotations']\n    self.dir_img = directory[mode + '_Images']\n    self.labels = config['LABELS']\n    self.num_classes = config['NUM_classes']\n    self.ignore_negative = ignore_negative\n\n  def test_dim(self, x):\n    for dim in x:\n      if int(dim * 1000) < 0. or (dim * 1000) > 1000: return False\n    return True \n\n  def generator(self):\n    for ann in sorted(os.listdir(self.dir_annot)):\n      if \"xml\" not in ann: continue\n      tree = ET.parse(self.dir_annot + ann)\n      X1, Y1, X2, Y2, conf, label = [[] for _ in range(6)]; \n      for elem in tree.iter():\n        if 'filename' in elem.tag:\n          with tf.io.gfile.GFile(self.dir_img + elem.text, 'rb') as f: \n            image_raw = f.read()\n        if 'width' in elem.tag: width = float(elem.text)\n        if 'height' in elem.tag: height = float(elem.text)\n        if 'object' in elem.tag or 'part' in elem.tag:  \n          for attr in list(elem):\n            if 'name' in attr.tag:\n              label_exist = attr.text in self.labels\n              if not label_exist: continue\n              label_id = self.labels.index(attr.text)\n            if 'bndbox' in attr.tag and label_exist:\n              box_size = 0\n              for i, dim in enumerate(list(attr)):\n                if 'xmin' in dim.tag:\n                  xmin = float(dim.text) / width\n                  box_size += 1\n                if 'ymin' in dim.tag:\n                  ymin = float(dim.text) / height\n                  box_size += 1\n                if 'xmax' in dim.tag:\n                  xmax = float(dim.text) / width\n                  box_size += 1\n                if 'ymax' in dim.tag:\n                  ymax = float(dim.text) / height\n                  box_size += 1\n                if box_size == 4:\n                  if not self.test_dim([xmin, ymin, xmax, ymax]): continue\n                  X1.append(xmin); Y1.append(ymin); X2.append(xmax); Y2.append(ymax)\n                  label.append(label_id)\n                  conf.append(1)\n      if len(X1) != len(conf) or (len(conf) < 1 and self.ignore_negative): continue\n      example = tf.train.Example(features=tf.train.Features(feature={\n        'encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_raw])),\n        'xmin':  tf.train.Feature(float_list=tf.train.FloatList(value=X1)),\n        'ymin':  tf.train.Feature(float_list=tf.train.FloatList(value=Y1)),\n        'xmax':  tf.train.Feature(float_list=tf.train.FloatList(value=X2)),\n        'ymax':  tf.train.Feature(float_list=tf.train.FloatList(value=Y2)),\n        'confidence':  tf.train.Feature(float_list=tf.train.FloatList(value=conf)),\n        'label': tf.train.Feature(float_list=tf.train.FloatList(value=label)),\n      }))\n      yield example\n\nclass Dataset_Transformation:\n  def __init__(self, config):\n    self.config = config\n    self.anchors = config[\"ANCHORS\"]\n    self.grid_size = config['INPUT_shape'][0] // 16\n    self.transformed_shape = config['INPUT_shape'][:2]\n    self.NUM_classes = config['NUM_classes']\n    self.NUM_anchors = config['ANCHORS_shape'][1]\n\n  def __call__(self, x, y):\n    y, anchor_mask = self.prepare_dataset(y)\n    output_1 = self.transform_output(y, anchor_mask, 0, self.grid_size)\n    output_2 = self.transform_output(y, anchor_mask, 1, self.grid_size * 2)\n    output_3 = self.transform_output(y, anchor_mask, 2, self.grid_size * 4)\n    return x, tuple([output_1, output_2, output_3])\n\n  def prepare_dataset(self, y):\n    batch_size = tf.shape(y)[0]\n    box_xy = tf.clip_by_value(y[..., :4], 0., 1.)\n    box_wh = box_xy[..., 2:4] - box_xy[..., 0:2]\n    box_wh = tf.tile(box_wh[..., tf.newaxis, :], [1, 1, self.anchors.shape[0], 1])\n    box_area = box_wh[..., 0] * box_wh[..., 1]\n    anchor_area = self.anchors[..., 0] * self.anchors[..., 1]\n    intersection = tf.minimum(box_wh[..., 0, tf.newaxis], self.anchors[..., 0]) * tf.minimum(box_wh[..., 1, tf.newaxis], self.anchors[..., 1])\n    iou = intersection / (anchor_area + box_area[..., tf.newaxis] - intersection)\n    anchor_max_iou = tf.cast(tf.argmax(iou, axis=-1), tf.int32)\n    labels = tf.one_hot(tf.cast(y[..., 5], tf.int32), self.NUM_classes)\n    y_dataset = tf.concat([box_xy, y[..., 4:5], labels], -1)\n    return y_dataset, anchor_max_iou\n\n  def transform_output(self, y, anchor_mask, step, grid_size):\n    batch_size = tf.shape(y)[0]\n    size = tf.shape(y)[1]\n    outputs = tf.zeros([batch_size, grid_size, grid_size, self.NUM_anchors, self.NUM_classes + 5])\n    if tf.math.greater(tf.shape(y)[0], tf.constant([0])):\n      box = y[..., 0:4]\n      box_xy = (y[..., 0:2] + y[..., 2:4]) / 2\n      grid_xy = tf.cast(box_xy // (1 / grid_size), tf.int32)\n      idx_batch = tf.reshape(tf.repeat(tf.range(batch_size), size), [batch_size, size, 1])\n      idx_non_zero = tf.where(y[..., 4])\n      idx = tf.concat([idx_batch, grid_xy[..., 1, tf.newaxis], grid_xy[..., 0, tf.newaxis],  anchor_mask[..., step, tf.newaxis]], axis=-1)\n      idx = tf.gather_nd(idx, idx_non_zero)\n      y = tf.gather_nd(y, idx_non_zero)\n      outputs = tf.tensor_scatter_nd_update(outputs, idx, y)\n    return outputs\n\ndef parse_tfrecord(tfrecord, size):\n    example = tf.io.parse_single_example(tfrecord, {\n        'encoded': tf.io.FixedLenFeature([], tf.string),\n        'xmin': tf.io.VarLenFeature(tf.float32),\n        'ymin': tf.io.VarLenFeature(tf.float32),\n        'xmax': tf.io.VarLenFeature(tf.float32),\n        'ymax': tf.io.VarLenFeature(tf.float32),\n        'confidence': tf.io.VarLenFeature(tf.float32),\n        'label': tf.io.VarLenFeature(tf.float32)})\n\n    x = tf.image.decode_png(example['encoded'], channels=3)\n    x = tf.cast(x, tf.uint8)\n    y = tf.stack(\n        [tf.sparse.to_dense(example['xmin']),\n         tf.sparse.to_dense(example['ymin']),\n         tf.sparse.to_dense(example['xmax']),\n         tf.sparse.to_dense(example['ymax']),\n         tf.sparse.to_dense(example['confidence']),\n         tf.sparse.to_dense(example['label'])], axis=1)\n    return x, y","metadata":{"scrolled":true,"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Write TFRecords","metadata":{}},{"cell_type":"code","source":"def RecordWriter(config, directory):\n  NUM_samples = []\n  for mode in ['TRAIN', 'VALIDATION', 'TEST']:\n    ignore_negative = True \n    if mode == 'TRAIN': \n      filename = 'Train.tfrecords'\n      print('Writing Train TFRecords')\n    elif mode == 'VALIDATION': \n      ignore_negative = True\n      filename = 'Validation.tfrecords'\n      print('Writing Validation TFRecords')  \n    else: \n      ignore_negative = True\n      filename = 'Test.tfrecords'\n      print('Writing Test TFRecords')\n        \n    i = 0\n    Data_Iterator = Data_Generator_VOC(config, directory, ignore_negative, mode=mode)\n    writer = tf.io.TFRecordWriter(filename)\n\n    for example in Data_Iterator.generator():\n      i += 1\n      writer.write(example.SerializeToString())\n    writer.close()\n    NUM_samples.append(i)\n  return NUM_samples\nNUM_samples = RecordWriter(config, directory)\nprint(NUM_samples)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transforms and Augmentation Pipeline","metadata":{}},{"cell_type":"code","source":"class Dataset_Augmentation:\n  def __init__(self, size, resize_only=False):\n    if resize_only:\n      self.augment_pipeline = A.Compose([\n        A.LongestMaxSize(max_size=size, always_apply=True),\n        A.PadIfNeeded(min_height=size, min_width=size, border_mode=0, value=(0,0,0)),\n        ], bbox_params=A.BboxParams(format='albumentations', label_fields=['index']))\n    else:\n      self.augment_pipeline = A.Compose([\n        A.RandomBrightnessContrast(p=0.8, brightness_limit=(-0.1, 0.25), contrast_limit=(-0.1, 0.25)),\n        A.ToGray(0.4),\n        A.OneOf([\n          A.GaussianBlur(p=0.5, blur_limit=(3, 5)),\n          A.MotionBlur(p=0.5, blur_limit=3)\n        ], p=0.8),\n        A.Sharpen(p=0.5),\n        A.HorizontalFlip(p=0.5),\n        A.ShiftScaleRotate(p=0.95, rotate_limit=20, scale_limit=(-0.4, 0.4), shift_limit=0.4, border_mode=cv.BORDER_CONSTANT,),\n      ], bbox_params=A.BboxParams(format='albumentations', min_visibility=0.7, label_fields=['index']))\n\n  def method(self, x, y, c):\n    transformed = self.augment_pipeline(image=x, bboxes=y, index=c)\n    return tf.cast(transformed['image'], tf.uint8), tf.cast(transformed['bboxes'], tf.float32), tf.cast(transformed['index'], tf.float32)\n\n  def __call__(self, x, y):\n    x, bbox, labels = tf.numpy_function(func=self.method, inp=[x, y[..., :4], y[..., 5]], Tout=[tf.uint8, tf.float32, tf.float32], stateful=False)\n    if tf.shape(bbox)[0] > 0:\n      y = tf.concat([bbox, tf.ones([tf.shape(bbox)[0], 1]), labels[..., tf.newaxis]], axis=-1)\n    else:\n      y = tf.reshape(tf.convert_to_tensor(()), (0, 6))\n    return x, y\n\n\ndef Dataset_Pipeline(config, batch_size, record_path, augment=False, cache=True, repeat=True, shuffle=True, cache_path='cache'):\n  size = config['INPUT_shape'][0]\n  options = tf.data.Options()\n  options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.AUTO\n  Dataset = tf.data.TFRecordDataset(record_path)\n  Dataset = Dataset.map(lambda x: parse_tfrecord(x, size), num_parallel_calls=tf.data.AUTOTUNE)\n  Dataset = Dataset.map(Dataset_Augmentation(size, resize_only=True), num_parallel_calls=tf.data.AUTOTUNE)\n  if cache:\n    Dataset = Dataset.cache(cache_path)\n  if repeat: \n    Dataset = Dataset.repeat()\n  if shuffle:\n    Dataset = Dataset.shuffle(buffer_size=2048)\n  if augment:\n    Dataset = Dataset.map(Dataset_Augmentation(size, resize_only=False), num_parallel_calls=tf.data.AUTOTUNE)\n  Dataset = Dataset.padded_batch(batch_size, padded_shapes=([size, size, 3], [20, 6]), drop_remainder=True)\n  Dataset = Dataset.map(Dataset_Transformation(config), num_parallel_calls=tf.data.AUTOTUNE)\n  Dataset = Dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n  return Dataset.with_options(options)\n\nNUM_samples = [4395, 399, 498]\nbatch_size = 64\nNUM_steps_per_epoch = (NUM_samples[0] // batch_size)\n\nDataset_Train = Dataset_Pipeline(config, batch_size, augment=True, shuffle=True, record_path='Train.tfrecords', cache_path='Train_Cache')\nDataset_Valid = Dataset_Pipeline(config, NUM_samples[1], repeat=False, shuffle=False, record_path='Validation.tfrecords', cache_path='Validation_Cache')\nDataset_Test = Dataset_Pipeline(config, NUM_samples[2], repeat=False, shuffle=False, record_path='Test.tfrecords', cache_path='Test_Cache')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cache Datasets on Disk","metadata":{}},{"cell_type":"code","source":"tfds.benchmark(Dataset_Valid, batch_size=NUM_samples[1])\ntfds.benchmark(Dataset_Test, batch_size=NUM_samples[2])\ntfds.benchmark(Dataset_Train, num_iter=NUM_steps_per_epoch + 1, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualization","metadata":{}},{"cell_type":"code","source":"for i, j in enumerate(Dataset_Train):\n  print(j[0].shape)\n  imageS = j[0]\n  trueS = j[1][0][0]\n  print(trueS.shape)\n  used_mem = psutil.virtual_memory().used\n  print(\"used memory: {} Mb\".format(used_mem / 1024 / 1024))\n  if i == 0: break\n\nPlot_Bbox(imageS[0], trueS)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.remove( '/kaggle/working/Test_Cache.index')\n#os.remove('/kaggle/working/Test_Cache.data-00000-of-00001')\n#os.remove( '/kaggle/working/Validation_Cache.index')\n#os.remove('/kaggle/working/Validation_Cache.data-00000-of-00001')\n#os.remove( '/kaggle/working/Train_Cache.index')\n#os.remove('/kaggle/working/Train_Cache.data-00000-of-00001')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def Conv_SiLU(x, filters, kernel_size, strides=1, depth_multiplier=1, mode='Conv2D', batch_norm=True):\n  if mode == 'SeparableConv2D':\n    x = SeparableConv2D(\n            filters=filters,\n            kernel_size=kernel_size,\n            strides=strides,\n            padding='same',\n            depth_multiplier=depth_multiplier,\n            pointwise_initializer=tf.initializers.variance_scaling(),\n            depthwise_initializer=tf.initializers.variance_scaling(),\n            use_bias=not batch_norm\n    )(x)\n  else:\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size, \n               strides=strides, \n               padding='same', \n               use_bias=not batch_norm, \n               kernel_regularizer=l2(0.0005), \n               kernel_initializer='he_normal')(x)\n  if batch_norm:\n    x = BatchNormalization()(x)\n    x = tf.nn.silu(x)\n  return x\n\ndef Conv_MOD(x, filters):\n  x = Conv_SiLU(x, filters, 1)\n  x = Conv_SiLU(x, filters, 3)\n  return x\n\nclass PAN:\n  def __init__(self, Conv):\n    self.Conv = Conv\n    \n  def Conv_Block(self, x, filters):\n    x = DepthwiseConv2D(kernel_size=3, strides=1, padding='same')(x)\n    x = BatchNormalization(synchronized=True)(x)\n    x = tf.nn.silu(x)\n    x = self.Conv(x, filters, 1)\n    return x\n\n  def Detection_Block(self, x, C_in, C_out=None):\n    if C_out == None: C_out = C_in\n    x_1 = self.Conv(x, C_in / 2, 1)\n    x_2 = self.Conv(x, C_in / 2, 1)\n    for _ in range(architecture['Det_Blocks']):\n      x_2 = self.Conv_Block(x_2, C_in / 2)\n    x = Concatenate()([x_1, x_2])\n    x = self.Conv(x, C_out, 1)\n    return x\n\n  def SPPF(self, t, filters, pool_size=5, name='SPPF'):\n    pool = MaxPool2D(pool_size, 1, padding='same')\n    x = inputs = Input(t.shape[1:])\n    x = self.Conv(x, filters // 2, 1)\n    p_1 = pool(x)\n    p_2 = pool(p_1)\n    p_3 = pool(p_2)\n    x = tf.concat([x, p_1, p_2, p_3], axis=-1)\n    x = self.Conv(x, filters, 1)\n    return Model(inputs, x, name=name)(t)\n    \n  def FPN_head(self, t, filters, conv=True, name=None):\n    if isinstance(t, tuple):\n      inputs = Input(t[0].shape[1:]), Input(t[1].shape[1:])\n      x, x_skip = inputs\n      x = UpSampling2D(2, interpolation='bilinear')(x)\n      x = Concatenate()([x, x_skip])\n      x = self.Detection_Block(x, filters)\n      if conv: x = self.Conv(x, filters // 2, 1)\n    else:\n      x = inputs = Input(t.shape[1:])\n      x = self.Conv(x, filters, 1)\n    return Model(inputs, x, name=name)(t)\n\n  def PAN_head(self, t, filters, name=None):\n    inputs = Input(t[0].shape[1:]), Input(t[1].shape[1:])\n    x, y = inputs\n    x = self.Conv(x, filters, 3, 2)\n    x = Concatenate()([x, y])\n    x = self.Detection_Block(x, C_in=filters, C_out=filters*2)\n    return Model(inputs, x, name=name)(t)\n\n  def __call__(self, x_in):\n    x_1, x_2, x_3 = x_in\n    x_3 = self.SPPF(x_3, architecture['SPPF_C'])\n    x_3 = y_3 = self.FPN_head(x_3, architecture['Neck_C'][1], name='FPN_13')\n    x_3 = y_2 = self.FPN_head((x_3, x_2), architecture['Neck_C'][1], name='FPN_26')\n    x_3 = y_1 = self.FPN_head((x_3, x_1), architecture['Neck_C'][0], conv=False, name='PAN_52')\n    y_2 = self.PAN_head((y_1, y_2), architecture['Neck_C'][0], name='PAN_26')\n    y_3 = self.PAN_head((y_2, y_3), architecture['Neck_C'][1], name='PAN_13')\n    return (y_1, y_2, y_3)\n\ndef Decoupled_Head(filters, NUM_anchors, NUM_classes, name=None):\n  class Head_Transformation(keras.layers.Layer):\n    def __init__(self, NUM_anchors, NUM_classes):\n      super().__init__()\n      self.NUM_anchors = NUM_anchors\n      self.NUM_classes = NUM_classes\n    def call(self, x):\n      return tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], self.NUM_anchors, self.NUM_classes + 5))\n\n  def builder(t):\n    x = inputs = Input(t.shape[1:])\n    x_1 = x_2 = Conv_SiLU(x, architecture['Head_C'], 1)\n    for _ in range(architecture['Head_Blocks']):\n      x_1 = Conv_SiLU(x_1, architecture['Head_C'], 3)\n      x_2 = Conv_SiLU(x_2, architecture['Head_C'], 3)\n    x_Cls = Conv_SiLU(x_1, NUM_anchors * (NUM_classes), 1, batch_norm=False)\n    x_Box = Conv_SiLU(x_2, NUM_anchors * 4, 1, batch_norm=False)\n    x_Conf = Conv_SiLU(x_2, NUM_anchors * 1, 1, batch_norm=False)\n    x = tf.concat([x_Box, x_Conf, x_Cls], axis=-1)\n    x = Head_Transformation(NUM_anchors, NUM_classes)(x)\n    return tf.keras.Model(inputs, x, name=name)(t)\n  return builder\n\nclass Output_Activation(tf.keras.layers.Layer):\n  def __init__(self, NUM_classes, anchors, GS_alpha, WH_power, training=False):\n    super().__init__()\n    self.training = training\n    self.NUM_classes = NUM_classes\n    self.anchors = anchors\n    self.GS_alpha = GS_alpha\n    self.WH_power = WH_power\n\n  def call(self, x):\n    grid_size = tf.shape(x)[1:3]\n    box_xy, box_wh, confidence, class_probs = tf.split(x, (2, 2, 1, self.NUM_classes), axis=-1)\n    box_xy = tf.sigmoid(box_xy)\n    box_wh = ((2 * tf.sigmoid(box_wh)) ** self.WH_power) * self.anchors\n    \n    if not self.training:\n      confidence = tf.sigmoid(confidence)\n      class_probs = tf.sigmoid(class_probs)\n\n    grid = tf.meshgrid(tf.range(grid_size[0]), tf.range(grid_size[1]))\n    grid = tf.stack(grid, axis=-1)[..., tf.newaxis, :]\n    box_xy = (self.GS_alpha * box_xy - (self.GS_alpha - 1) / 2 + tf.cast(grid, x.dtype)) / tf.cast(grid_size, x.dtype)\n    box_x1y1 = box_xy - box_wh / 2\n    box_x2y2 = box_xy + box_wh / 2\n    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n    return bbox, confidence, class_probs\n\nclass EfficientNetV2:\n  def __init__(self, mode='EfficientNetV2S', trainable=True):\n    self.config = ['block2c_add', 'block4a_expand_activation', 'block6a_expand_activation']\n    if mode == 'EfficientNetV2B0': \n        self.model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0\n        self.config = ['block2b_add', 'block4a_expand_activation', 'block6a_expand_activation']\n    elif mode == 'EfficientNetV2B1': self.model = tf.keras.applications.efficientnet_v2.EfficientNetV2B1\n    elif mode == 'EfficientNetV2B2': self.model = tf.keras.applications.efficientnet_v2.EfficientNetV2B2\n    elif mode == 'EfficientNetV2B3': self.model = tf.keras.applications.efficientnet_v2.EfficientNetV2B3\n    else:\n      mode = 'EfficientNetV2S'\n      self.model = tf.keras.applications.efficientnet_v2.EfficientNetV2S\n    \n    self.model = self.model(include_top=False,\n                            weights='imagenet',\n                            input_tensor=None,\n                            input_shape=None,\n                            include_preprocessing=False,\n                            classifier_activation=None)\n    self.mode = mode\n    self.trainable = trainable\n  \n  def __call__(self):\n    x = inputs = Input([None, None, 3])\n    m = Model(inputs=self.model.inputs, outputs=self.model.get_layer(self.config[0]).output)\n    n = Model(inputs=m.inputs, outputs = self.model.get_layer(self.config[1]).output)\n    o = Model(inputs=n.inputs, outputs=(m.output, n.output, self.model.get_layer(self.config[2]).output))\n    x = o(x)\n    model = Model(inputs=inputs, outputs=x, name=self.mode)\n    model.trainable = self.trainable\n    return model\n\nclass Post_Process(keras.layers.Layer):\n  def __init__(self, NUM_classes, max_boxes=25, IoU_thresh=0.5, score_thresh=0.55):\n    super().__init__()\n    self.NUM_classes = NUM_classes\n    self.max_boxes = max_boxes\n    self.IoU_thresh = IoU_thresh\n    self.score_thresh = score_thresh\n\n  def NMS(self, outputs):\n    bbox, confidence, class_probs = [], [], []\n    for o in outputs:\n      bbox.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n      confidence.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n      class_probs.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n\n    bbox = tf.maximum(tf.concat(bbox, axis=1), 0.)[..., tf.newaxis, :]\n    confidence = tf.concat(confidence, axis=1)\n    class_probs = tf.concat(class_probs, axis=1)\n    \n    if self.NUM_classes == 1: scores = confidence\n    else: scores = confidence * class_probs\n    \n    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n        boxes=tf.cast(XYXY_to_YXYX(bbox), tf.float32),\n        scores=tf.cast(scores, tf.float32),\n        max_output_size_per_class=self.max_boxes,\n        max_total_size=self.max_boxes,\n        iou_threshold=self.IoU_thresh,\n        score_threshold=self.score_thresh)\n\n    return boxes, scores, classes, valid_detections\n\n  def call(self, x):\n    x = self.NMS(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Architecture","metadata":{}},{"cell_type":"code","source":"def YOLOv3_MOD(Backbone, Neck, Head, SHAPE_input, NUM_anchors, NUM_classes, training=True):\n  x = inputs = Input(SHAPE_input, name='input')\n  if not training:\n    x = tf.image.resize_with_pad(x, SHAPE_input[0], SHAPE_input[1])\n  x = tf.keras.layers.Rescaling(scale=1./255.)(x)\n  x = Backbone()(x)\n  y_1, y_2, y_3 = Neck(x)\n  y_3 = Head(240, NUM_anchors, NUM_classes, 'Head_13')(y_3)\n  y_2 = Head(120, NUM_anchors, NUM_classes, 'Head_26')(y_2)\n  y_1 = Head(60, NUM_anchors, NUM_classes, 'Head_52')(y_1)\n  y = [y_3, y_2, y_1]\n  if training: \n    return Model(inputs, y, name='YOLOv3_MOD')\n  else:\n    y = [Output_Activation(config['NUM_classes'], \n                           config['ANCHORS'][level], \n                           config['PARAMS_GS_alpha'][level], \n                           config['PARAMS_WH_power'][level], \n                           training=False)(y[level]) for level in [0, 1, 2]]\n    y = Post_Process(NUM_classes)(y)\n  \n  return Model(inputs, y, name='YOLOv3_MOD')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss Function","metadata":{}},{"cell_type":"code","source":"class Loss():\n  def __init__(self, Output_Activation, NUM_classes, anchors, GS_alpha, WH_power, head_scale=1.0, conf_scale=0.01, IoU_thresh=0.6, name=None):\n    self.Output_Activation = Output_Activation(NUM_classes, anchors, GS_alpha, WH_power, training=True)\n    self.NUM_classes = NUM_classes\n    self.anchors = anchors\n    self.GS_alpha = GS_alpha\n    self.IoU_thresh = IoU_thresh\n    self.head_scale = head_scale\n    self.conf_scale = conf_scale\n    self.name = name\n\n  def get_v(self, A_H, A_W, B_H, B_W):\n    @tf.custom_gradient\n    def forward(height, width):\n      arctan = tf.atan(tf.math.divide_no_nan(A_W, A_H)) - tf.atan(tf.math.divide_no_nan(width, height))\n      v = 4 * ((arctan / math.pi) ** 2)\n      def grad(dv):\n        gdw = dv * 8 * arctan * height / (math.pi ** 2)\n        gdh = -dv * 8 * arctan * width / (math.pi ** 2)\n        return [gdh, gdw]\n      return v, grad\n    return forward(B_H, B_W)\n  \n  def Bbox_IoU(self, A, B, loss=None):\n    A_X1, A_Y1, A_X2, A_Y2 = tf.split(A, (1, 1, 1, 1), axis=-1)\n    B_X1, B_Y1, B_X2, B_Y2 = tf.split(B, (1, 1, 1, 1), axis=-1)\n    A_W, A_H = tf.maximum(0., A_X2 - A_X1), tf.maximum(0., A_Y2 - A_Y1)\n    B_W, B_H = tf.maximum(0., B_X2 - B_X1), tf.maximum(0., B_Y2 - B_Y1)\n    A_area, B_area = A_W * A_H, B_W * B_H\n    inter_X1, inter_X2 = tf.maximum(A_X1, B_X1), tf.minimum(A_X2, B_X2)\n    inter_Y1, inter_Y2 = tf.maximum(A_Y1, B_Y1), tf.minimum(A_Y2, B_Y2)\n    inter_W, inter_H = tf.maximum(0., inter_X2 - inter_X1), tf.maximum(0., inter_Y2 - inter_Y1)\n    inter_area =  inter_W * inter_H\n    union_area = A_area + B_area - inter_area\n    IoU = tf.math.divide_no_nan(inter_area, union_area)\n    \n    if loss in ['GIoU', 'DIoU', 'CIoU']:\n      C_X1, C_X2 = tf.minimum(A_X1, B_X1), tf.maximum(A_X2, B_X2)\n      C_Y1, C_Y2 = tf.minimum(A_Y1, B_Y1), tf.maximum(A_Y2, B_Y2)\n    \n      if loss in ['DIoU', 'CIoU']:\n        l2_2 = (((B_X1 + B_X2) - (A_X1 + A_X2)) ** 2) / 4 + (((B_Y1 + B_Y2) - (A_Y1 + A_Y2)) ** 2) / 4\n        diag_2 = (C_Y2 - C_Y1) ** 2 + (C_X2 - C_X1) ** 2\n        DIoU = IoU - tf.math.divide_no_nan(l2_2, diag_2)\n        if loss == 'DIoU':\n          return IoU, 1. - DIoU\n        v = self.get_v(A_H, A_W, B_H, B_W)\n        alpha = tf.stop_gradient(tf.math.divide_no_nan(v, (1 - IoU) + v))\n        CIoU = DIoU - alpha * v\n        return IoU, 1. - CIoU\n\n      if loss == 'GIoU':\n        C_W = tf.maximum(0., C_X2 - C_X1)\n        C_H = tf.maximum(0., C_Y2 - C_Y1)\n        C_area = C_W * C_H\n        GIoU = IoU - tf.math.divide_no_nan((C_area - union_area), C_area)\n        return IoU, 1. - GIoU\n\n    return IoU, 1. - IoU\n\n  def logit(self, x):\n    return - tf.math.log(1 / x - 1)\n\n  def __call__(self, y_true, y_pred):\n    pred_box, pred_obj, pred_class = self.Output_Activation(y_pred)\n    true_box, true_obj, true_class = tf.split(y_true, (4, 1, self.NUM_classes), axis=-1)\n    \n    IoU, Loss_IoU = self.Bbox_IoU(true_box, pred_box, loss='CIoU')\n\n    max_IoU = tf.reduce_max(IoU, axis=-1)\n    ignore_mask = tf.stop_gradient(tf.cast(max_IoU < self.IoU_thresh, tf.float32))\n    obj_mask = tf.squeeze(true_obj, axis=-1)\n    conf_Loss_scale = tf.squeeze((true_obj - tf.sigmoid(pred_obj)) ** 2, axis=-1)\n  \n    Loss_IoU = tf.squeeze(Loss_IoU, axis=-1) * obj_mask\n    \n    Loss_conf = BinaryCrossentropy(from_logits=True, reduction='none')(true_obj, pred_obj)\n    Loss_conf = conf_Loss_scale * (Loss_conf * obj_mask + self.conf_scale * (1 - obj_mask) * Loss_conf * ignore_mask)\n\n    Loss_class = BinaryCrossentropy(from_logits=True,  reduction='none')(true_class, pred_class)\n    Loss_class = Loss_class * obj_mask\n\n    Loss_IoU = tf.reduce_mean(tf.reduce_sum(Loss_IoU, axis=[1,2,3]))\n    Loss_conf = tf.reduce_mean(tf.reduce_sum(Loss_conf, axis=[1,2,3]))\n    Loss_class = tf.reduce_mean(tf.reduce_sum(Loss_class, axis=[1,2,3]))\n    Loss_total = (Loss_IoU * 2 + Loss_conf + Loss_class * 2) * self.head_scale\n    return Loss_total","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summarize Model","metadata":{}},{"cell_type":"code","source":"structure = [EfficientNetV2(mode=architecture['backbone'], trainable=True), PAN(Conv_SiLU), Decoupled_Head]\narch = YOLOv3_MOD(*structure, config['INPUT_shape'], config['ANCHORS_shape'][1], config['NUM_classes'], training=True)\narch.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"NUM_steps_per_epoch = (NUM_samples[0] // batch_size)\n\ndef Plot_learning_rate(lr, steps_per_epoch, epochs=100):\n  steps = tf.range((NUM_samples[0] // batch_size)*epochs)\n  rate = lr(steps)\n  plt.plot(steps / steps_per_epoch, rate)\n  plt.show()\n\nlr_CosineDecayRestarts = tf.keras.optimizers.schedules.CosineDecayRestarts(\n    initial_learning_rate=0.001, m_mul=0.4, t_mul=1,\n    first_decay_steps=NUM_steps_per_epoch*80)\n\nlr_PiecewiseConstantDecay = keras.optimizers.schedules.PiecewiseConstantDecay(\n    boundaries=[int(c*NUM_steps_per_epoch) for c in [130, 180, 230]], \n    values=[0.001, 0.0003, 0.0001, 0.00005])\n\nPlot_learning_rate(lr_CosineDecayRestarts, NUM_steps_per_epoch, 320)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(model, epochs, resume=False, freeze_backbone=True, warmup=False, load_last=False, load_checkpoint=False):\n  if not resume:\n    if not freeze_backbone: model.trainable = True\n    if load_last: model.load_weights('weights_last.h5')\n    if load_checkpoint: model.load_weights('weights_checkpoint.h5')\n    fit_config = [[\n      config['NUM_classes'], \n      config['ANCHORS'][level], \n      config['PARAMS_GS_alpha'][level], \n      config['PARAMS_WH_power'][level], \n      config['PARAMS_head_scale'][level],\n      config['PARAMS_conf_scale'][level]] for level in tf.range(3)]\n    loss = [Loss(Output_Activation, *fit_config[level], name='Loss') for level in tf.range(3)]\n    \n    if warmup:\n      learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n            boundaries=[int(c*NUM_steps_per_epoch) for c in [1, 2, 3, 4, 5, 6, 7, 8, 9, 150, 225, 250, 300]],\n            values=[1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-5, 1e-4, 1e-4, 1e-3, 0.001, 0.0003, 0.00006, 0.0001, 0.00001])\n\n    else:\n      learning_rate = lr_CosineDecayRestarts = tf.keras.optimizers.schedules.CosineDecayRestarts(\n          initial_learning_rate=0.001, m_mul=0.4, t_mul=1,\n          first_decay_steps=NUM_steps_per_epoch*80)\n\n        \n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), jit_compile=True, steps_per_execution=1, loss=loss)\n    \n  callbacks = [\n      ModelCheckpoint(filepath='weights_checkpoint.h5', save_weights_only=True,  monitor='val_loss', save_best_only=True),\n      CSVLogger('log.csv', separator=',', append=True)]\n\n  hist = model.fit(\n       Dataset_Train,\n       validation_data=Dataset_Valid,\n       epochs=epochs,\n       callbacks=callbacks,\n       steps_per_epoch=NUM_samples[0] // batch_size,\n       validation_steps=1)  \n  model.save_weights('weights_last.h5')\n  return hist\n\nNUM_steps_per_epoch = (NUM_samples[0] // batch_size)\nwith strategy.scope():\n  structure = [EfficientNetV2(mode=architecture['backbone'], trainable=True), PAN(Conv_SiLU), Decoupled_Head]\n  model = YOLOv3_MOD(*structure, config['INPUT_shape'], config['ANCHORS_shape'][1], config['NUM_classes'], training=True)\n\nhistory = fit(model, 150, load_last=False, freeze_backbone=False, resume=False, warmup=True)\nhistory = fit(model, 320, load_last=False, freeze_backbone=False, resume=False, warmup=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"for full_batch in Dataset_Test: \n      x_true = full_batch[0]\n      y_true = full_batch[1][0]\ny_pred = model_test.predict(x_true, verbose=0)\ny_pred = [Output_Activation(config['NUM_classes'], \n                           config['ANCHORS'][level], \n                           config['PARAMS_GS_alpha'][level], \n                           config['PARAMS_WH_power'][level], \n                           training=False)(y_pred[level]) for level in [0, 1, 2]]\ny_pred = Post_Process(2, 30, 0.1, 0.5)(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef IoU(A, B):\n  A_X1, A_Y1, A_X2, A_Y2 = tf.split(A, (1, 1, 1, 1), axis=-1)\n  B_X1, B_Y1, B_X2, B_Y2 = tf.split(B, (1, 1, 1, 1), axis=-1)\n  A_W, A_H = tf.maximum(0., A_X2 - A_X1), tf.maximum(0., A_Y2 - A_Y1)\n  B_W, B_H = tf.maximum(0., B_X2 - B_X1), tf.maximum(0., B_Y2 - B_Y1)\n  A_area, B_area = A_W * A_H, B_W * B_H\n  inter_X1, inter_X2 = tf.maximum(A_X1, B_X1), tf.minimum(A_X2, B_X2)\n  inter_Y1, inter_Y2 = tf.maximum(A_Y1, B_Y1), tf.minimum(A_Y2, B_Y2)\n  inter_W, inter_H = tf.maximum(0., inter_X2 - inter_X1), tf.maximum(0., inter_Y2 - inter_Y1)\n  inter_area =  inter_W * inter_H\n  union_area = A_area + B_area - inter_area\n  IoU = tf.math.divide_no_nan(inter_area, union_area)\n  return IoU\n\nclass GC(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    gc.collect()\n\nclass mAP():\n  def __init__(self, Dataset, NUM_classes, per_class=False):\n    self.dataset = Dataset\n    self.stats = None\n    self.stats_true_boxes = None\n    self.stats_discard = 0.\n    self.NUM_classes = NUM_classes\n    self.per_class = per_class\n    self.metric = []\n\n  @tf.function\n  def compute_stats(self, pred_boxes, pred_scores, pred_classes, valid_detections, targets, thresh_IoU):\n    pred_boxes = XYXY_to_YXYX(pred_boxes)\n    idx_targets = tf.where(targets[..., 4])\n    idx_count, _, count = tf.unique_with_counts(idx_targets[:, 0])\n    valid_detections = valid_detections[:tf.shape(count)[0]]\n    targets = tf.gather_nd(targets, idx_targets)\n    NUM_pred = tf.reduce_sum(valid_detections)\n    NUM_true = tf.shape(idx_targets)[0]\n    idx_pred = tf.where(pred_boxes[..., 3])\n    true_boxes = targets[..., :4]\n    true_class = tf.cast(tf.where(targets[..., 5:]), tf.int32)[:,-1]\n    pred_boxes = tf.gather_nd(pred_boxes, idx_pred)\n    pred_classes = tf.gather_nd(pred_classes, idx_pred)\n    pred_scores = tf.gather_nd(pred_scores, idx_pred)\n    stats = tf.TensorArray(tf.float32, size=NUM_pred, clear_after_read=True)\n    stats_true_boxes = tf.TensorArray(tf.float32, size=self.NUM_classes, clear_after_read=True)\n    pos_true = pos_pred = count_true = count_pred = 0\n    for i in tf.range(NUM_pred):\n      stats = stats.write(i, [0., pred_classes[i], pred_scores[i]])\n    for i in tf.range(self.NUM_classes):\n      count_class = tf.reduce_sum(tf.cast(true_class == i, tf.float32))\n      stats_true_boxes = stats_true_boxes.write(i, tf.cast(count_class, tf.float32))\n    for i in tf.range(tf.shape(valid_detections)[0]):\n      if valid_detections[i] > 0:\n        true_box_i = true_boxes[count_true:(count_true + count[pos_true])]\n        pred_box_i = tf.tile(pred_boxes[pos_pred:(pos_pred + valid_detections[i]), tf.newaxis], [1, count[pos_true], 1])\n        IoU_i = IoU(true_box_i, pred_box_i)\n        IoU_thresh = tf.reduce_any(IoU_i > thresh_IoU, axis=0)\n        IoU_max = tf.argmax(IoU_i, axis=0, output_type=tf.int32)\n        for j in tf.range(count[pos_true]):\n          idx = pos_pred + tf.squeeze(IoU_max[j])\n          if IoU_thresh[j]:\n            stats = stats.write(idx, [1., pred_classes[idx], pred_scores[idx]])      \n      count_true += count[pos_true]\n      pos_true += 1\n      pos_pred += valid_detections[i]\n    return stats.stack(), stats_true_boxes.stack()\n\n  #@tf.function\n  def compute_AP(self, P, R):\n    P_interp = tf.scan(lambda a, b: tf.maximum(a, b), P, reverse=True)  \n    _, _, idx = tf.unique_with_counts(R)\n    idx = tf.cast(tf.scan(lambda a, b: a + b, idx) - idx, tf.int32)\n    P_curve = tf.gather(P_interp, idx)\n    R_curve = tf.gather(R, idx)\n    dR = tf.scan(lambda a, b: tf.maximum(b - a, 0.), R_curve, initializer=0.)\n    AUC = dR * P_curve\n    AP = tf.clip_by_value(tf.reduce_sum(AUC), 0., 1.)\n    return AP\n\n  def result(self):\n    idx_sort = tf.argsort(self.stats[..., -1], direction='DESCENDING') \n    x = tf.gather(self.stats, idx_sort, axis=0)\n    array = tf.TensorArray(tf.float32, size=self.NUM_classes, clear_after_read=True)\n    array_precision = tf.TensorArray(tf.float32, size=self.NUM_classes, clear_after_read=False, infer_shape=(None))\n    array_recall = tf.TensorArray(tf.float32, size=self.NUM_classes, clear_after_read=False, infer_shape=(None))\n    for idx_class in tf.range(self.NUM_classes):\n      mask_class = tf.cast(x[:, 1], tf.int32) == idx_class\n      x_class = tf.boolean_mask(x, mask_class, axis=0)\n      if tf.shape(x_class)[0] == 0:\n        array = array.write(idx_class, 0.)\n        if self.stats_true_boxes[idx_class] == 0: self.stats_discard += 1.\n      else:\n        cum_TP = tf.cumsum(x_class[:, 0])\n        cum_range = tf.cast(tf.range(1, tf.shape(x_class[:, 0])[0] + 1), tf.float32)\n        recall = tf.math.divide_no_nan(cum_TP, self.stats_true_boxes[idx_class])\n        precision = tf.math.divide_no_nan(cum_TP, cum_range)\n        array_precision = array_precision.write(idx_class, precision)\n        array_recall = array_recall.write(idx_class, recall)\n        #tf.print(2 * precision*recall/(precision + recall))\n        array = array.write(idx_class, self.compute_AP(precision, recall))\n    AP = array.stack()\n    if self.per_class: \n      return AP\n    else: \n      mAP = tf.math.divide_no_nan(tf.reduce_sum(AP), (self.NUM_classes - self.stats_discard))\n      self.stats_discard = 0\n      return mAP, array_precision, array_recall\n\n  def update(self, y_true, y_pred, thresh_IoU):\n    stats, stats_true_boxes = self.compute_stats(*y_pred, y_true, thresh_IoU)\n    if self.stats == None: \n        self.stats = stats\n        self.stats_true_boxes = stats_true_boxes\n    else: \n        self.stats = (tf.concat([self.stats, stats], axis=0))\n        self.stats_true_boxes += stats_true_boxes\n\n  def reset(self):\n    self.stats = None\n\n  def __call__(self, model):\n    gc.collect()\n    metric = []\n    \n    for thresh_IoU in [0.5, 0.6, 0.7]: #0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95\n        self.reset()\n        self.update(y_true, y_pred, thresh_IoU)\n        result = self.result()\n        metric.append(result[0])\n        r = result[1:]\n        print(thresh_IoU)\n        print(np.trapz(r[0].read(0), r[1].read(0)))\n        print(np.trapz(r[0].read(1), r[1].read(1)), '\\n')\n    metric = tf.reduce_mean(metric)\n    self.metric.append(metric)\n    return metric, r\n\nMAP = mAP(Dataset_Test, NUM_classes=2, per_class=False)\nmetric, result = MAP(model_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(result[1].read(0), result[0].read(0), label='W')\nplt.plot(result[1].read(1), result[0].read(1), label='C')\nplt.ylim(ymax = 1, ymin = 0.1)\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.legend(loc=\"upper right\")\nplt.savefig('PR.svg')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"log.csv\")\nimport pandas as pd\ndf = pd.read_csv(\"log.csv\")\nfig, ax = plt.subplots(figsize=(8, 5))\nplt.plot(df['val_loss'])\nplt.plot(df['loss'])\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['validation', 'train'], loc='upper right')\nplt.ylim(2., 50)\nplt.savefig('Loss.svg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef IoU(A, B):\n  A_X1, A_Y1, A_X2, A_Y2 = tf.split(A, (1, 1, 1, 1), axis=-1)\n  B_X1, B_Y1, B_X2, B_Y2 = tf.split(B, (1, 1, 1, 1), axis=-1)\n  A_W, A_H = tf.maximum(0., A_X2 - A_X1), tf.maximum(0., A_Y2 - A_Y1)\n  B_W, B_H = tf.maximum(0., B_X2 - B_X1), tf.maximum(0., B_Y2 - B_Y1)\n  A_area, B_area = A_W * A_H, B_W * B_H\n  inter_X1, inter_X2 = tf.maximum(A_X1, B_X1), tf.minimum(A_X2, B_X2)\n  inter_Y1, inter_Y2 = tf.maximum(A_Y1, B_Y1), tf.minimum(A_Y2, B_Y2)\n  inter_W, inter_H = tf.maximum(0., inter_X2 - inter_X1), tf.maximum(0., inter_Y2 - inter_Y1)\n  inter_area =  inter_W * inter_H\n  union_area = A_area + B_area - inter_area\n  IoU = tf.math.divide_no_nan(inter_area, union_area)\n  return IoU\n\nclass mAP():\n  def __init__(self, Dataset, NUM_classes, per_class=False):\n    self.dataset = Dataset\n    self.stats = None\n    self.stats_true_boxes = None\n    self.stats_discard = 0.\n    self.NUM_classes = NUM_classes\n    self.per_class = per_class\n    self.metric = []\n\n  @tf.function\n  def compute_stats(self, pred_boxes, pred_scores, pred_classes, valid_detections, targets, thresh_IoU):\n    pred_boxes = XYXY_to_YXYX(pred_boxes)\n    idx_targets = tf.where(targets[..., 4])\n    idx_count, _, count = tf.unique_with_counts(idx_targets[:, 0])\n    valid_detections = valid_detections[:tf.shape(count)[0]]\n    targets = tf.gather_nd(targets, idx_targets)\n    NUM_pred = tf.reduce_sum(valid_detections)\n    NUM_true = tf.shape(idx_targets)[0]\n    idx_pred = tf.where(pred_boxes[..., 3])\n    true_boxes = targets[..., :4]\n    true_class = tf.cast(tf.where(targets[..., 5:]), tf.int32)[:,-1]\n    pred_boxes = tf.gather_nd(pred_boxes, idx_pred)\n    pred_classes = tf.gather_nd(pred_classes, idx_pred)\n    pred_scores = tf.gather_nd(pred_scores, idx_pred)\n    stats = tf.TensorArray(tf.float32, size=NUM_pred, clear_after_read=True)\n    stats_true_boxes = tf.TensorArray(tf.float32, size=self.NUM_classes, clear_after_read=True)\n    pos_true = pos_pred = count_true = count_pred = 0\n    for i in tf.range(NUM_pred):\n      stats = stats.write(i, [0., pred_classes[i], pred_scores[i]])\n    for i in tf.range(self.NUM_classes):\n      count_class = tf.reduce_sum(tf.cast(true_class == i, tf.float32))\n      stats_true_boxes = stats_true_boxes.write(i, tf.cast(count_class, tf.float32))\n        \n    for i in tf.range(tf.shape(valid_detections)[0]):\n      if valid_detections[i] > 0:\n        true_box_i = true_boxes[count_true:(count_true + count[pos_true])]\n        pred_box_i = tf.tile(pred_boxes[pos_pred:(pos_pred + valid_detections[i]), tf.newaxis], [1, count[pos_true], 1])\n        IoU_i = IoU(true_box_i, pred_box_i)\n        IoU_thresh = tf.reduce_any(IoU_i > thresh_IoU, axis=0)\n        IoU_max = tf.argmax(IoU_i, axis=0, output_type=tf.int32)\n        for j in tf.range(count[pos_true]):\n          idx = pos_pred + tf.squeeze(IoU_max[j])\n          if IoU_thresh[j]:\n            stats = stats.write(idx, [1., pred_classes[idx], pred_scores[idx]])      \n      count_true += count[pos_true]\n      pos_true += 1\n      pos_pred += valid_detections[i]\n    return stats.stack(), stats_true_boxes.stack()\n\n\n  def compute_AP(self, P, R):\n    P_interp = tf.scan(lambda a, b: tf.maximum(a, b), P, reverse=True)  \n    _, _, idx = tf.unique_with_counts(R)\n    idx = tf.cast(tf.scan(lambda a, b: a + b, idx) - idx, tf.int32)\n    P_curve = tf.gather(P_interp, idx)\n    R_curve = tf.gather(R, idx)\n    dR = tf.scan(lambda a, b: tf.maximum(b - a, 0.), R_curve, initializer=0.)\n    AUC = dR * P_curve\n    AP = tf.clip_by_value(tf.reduce_sum(AUC), 0., 1.)\n    return AP\n\n  def result(self):\n    idx_sort = tf.argsort(self.stats[..., -1], direction='DESCENDING') \n    x = tf.gather(self.stats, idx_sort, axis=0)\n    array = tf.TensorArray(tf.float32, size=self.NUM_classes, clear_after_read=True)\n    array_precision = tf.TensorArray(tf.float32, size=self.NUM_classes, clear_after_read=False, infer_shape=(None))\n    array_recall = tf.TensorArray(tf.float32, size=self.NUM_classes, clear_after_read=False, infer_shape=(None))\n    for idx_class in tf.range(self.NUM_classes):\n      mask_class = tf.cast(x[:, 1], tf.int32) == idx_class\n      x_class = tf.boolean_mask(x, mask_class, axis=0)\n      if tf.shape(x_class)[0] == 0:\n        array = array.write(idx_class, 0.)\n        if self.stats_true_boxes[idx_class] == 0: self.stats_discard += 1.\n      else:\n        cum_TP = tf.cumsum(x_class[:, 0])\n        cum_range = tf.cast(tf.range(1, tf.shape(x_class[:, 0])[0] + 1), tf.float32)\n        recall = tf.math.divide_no_nan(cum_TP, self.stats_true_boxes[idx_class])\n        precision = tf.math.divide_no_nan(cum_TP, cum_range)\n        array_precision = array_precision.write(idx_class, precision[-1])\n        array_recall = array_recall.write(idx_class, recall[-1])\n        array = array.write(idx_class, self.compute_AP(precision, recall))\n    AP = array.stack()\n    if self.per_class: \n      return AP\n    else: \n      mAP = tf.math.divide_no_nan(tf.reduce_sum(AP), (self.NUM_classes - self.stats_discard))\n      self.stats_discard = 0\n      return mAP, array_precision, array_recall\n\n  def update(self, y_true, y_pred, thresh_IoU):\n    stats, stats_true_boxes = self.compute_stats(*y_pred, y_true, thresh_IoU)\n    if self.stats == None: \n        self.stats = stats\n        self.stats_true_boxes = stats_true_boxes\n    else: \n        self.stats = (tf.concat([self.stats, stats], axis=0))\n        self.stats_true_boxes += stats_true_boxes\n\n  def reset(self):\n    self.stats = None\n\n  def __call__(self, model):\n    gc.collect()\n    metric = []\n    PR = []\n    conf = tf.range(0.1, 0.9, 0.025)\n    \n    for i, y_pred in enumerate(y_pred_conf):\n        self.reset()\n        self.update(y_true, y_pred, 0.5)\n        result = self.result()\n        metric.append(result[0])\n        P, R = result[1:]\n        PR.append([conf[i], P.read(0), R.read(0), P.read(1), R.read(1)])\n\n    metric = tf.reduce_mean(metric)\n    self.metric.append(metric)\n    return metric, tf.stack(PR)\n\nMAP = mAP(Dataset_Test, NUM_classes=2, per_class=False)\nmetric, PR = MAP(model_test)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 5))\nplt.plot(PR[:, 0], PR[:, 1])\nplt.plot(PR[:, 0], PR[:, 2])\nplt.legend(['precision', 'recall'], loc='lower right')\nplt.xlabel('Confidence Threshold')\nplt.show()\n\nfig, ax = plt.subplots(figsize=(8, 5))\nplt.plot(PR[:, 0], PR[:, 3])\nplt.plot(PR[:, 0], PR[:, 4])\nplt.legend(['precision', 'recall'], loc='lower right')\nplt.xlabel('Confidence Threshold')\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in Dataset_Test: \n      x_true = batch[0]\n      y_true = batch[1][0]\n\ny_pred_conf = []\ny_pred = model_test.predict(x_true, verbose=0)\ny_pred = [Output_Activation(config['NUM_classes'], \n                           config['ANCHORS'][level], \n                           config['PARAMS_GS_alpha'][level], \n                           config['PARAMS_WH_power'][level], \n                           training=False)(y_pred[level]) for level in [0, 1, 2]]\n\nfor conf in tf.range(0.1, 0.9, 0.025):\n  y_pred_conf.append(Post_Process(2, 30, 0.5, conf)(y_pred))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save Weights","metadata":{}},{"cell_type":"code","source":"filepath_weights = \"weights_last.h5\"\nmodel.save_weights(filepath_weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"#!gdown 1_2xPFYOsfLegbRoVocyKgb7hjuzKJh5W\nwith strategy.scope():\n  model_test = YOLOv3_MOD(EfficientNetV2(mode='EfficientNetV2B1', trainable=True), PAN(Conv_SiLU), Decoupled_Head, config['INPUT_shape'], config['ANCHORS_shape'][1], config['NUM_classes'], training=True)\n  model_test.load_weights(\"weights_checkpoint.h5\") #weights_last","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nimage_ = tf.image.flip_left_right(image[19])\nimage_ = tfa.image.translate_xy(image_, [-120., 129.], replace=0.)\ny = model_test.predict(image_[tf.newaxis, ...])\ny = [Output_Activation(config['NUM_classes'], \n                           config['ANCHORS'][level], \n                           config['PARAMS_GS_alpha'][level], \n                           config['PARAMS_WH_power'][level], \n                           training=False)(y[level]) for level in [0, 1, 2]]\n\ny = Post_Process(2, 100, 0.45, 0.5)(y)\nPlot_Bbox_NMS(image_, XYXY_to_YXYX(y[0][0]), y[1][0], y[2][0])","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Plot_Bbox_NMS(image, boxes, scores, labels, name=None):\n  fig, ax = plt.subplots(figsize=(12, 8))\n  ax.imshow(tf.squeeze(image))\n  idx_non_zero = tf.where(scores)\n  boxes = tf.gather_nd(boxes, idx_non_zero)\n  scores = tf.gather_nd(scores, idx_non_zero)  \n  labels = tf.gather_nd(labels, idx_non_zero)\n  for box, label in zip(boxes, labels):\n    label = tf.cast(label, tf.int32)\n    box = box[..., :4] * config['INPUT_shape'][0]\n    xywh = XYXY_to_XYWH(box)\n    xywh = tf.squeeze(tf.cast(xywh, tf.int32))\n    box = tf.cast(box, tf.int32)\n    rect = patches.Rectangle((box[0], box[1]), xywh[2], xywh[3], linewidth=2.5, edgecolor=colors[label], facecolor='none')\n    ax.add_patch(rect)\n    ax.text(box[0], box[1] - 8, config['LABELS'][label], fontsize=12, color=colors[tf.squeeze(label)])\n  plt.axis('off');\n  if name:\n    plt.savefig(name)\n    plt.close(fig)\n  else:\n    plt.show()\n    \ndef draw_predictions(image, boxes, scores, labels, name=None):\n  image = tf.squeeze(image)\n  col = [[255, 165, 0], [106, 90, 205]]\n  idx_non_zero = tf.where(scores)\n  boxes = tf.cast(XYXY_to_YXYX(tf.gather_nd(boxes, idx_non_zero)) * config['INPUT_shape'][0], tf.int32)\n  scores = tf.gather_nd(scores, idx_non_zero)  \n  labels = tf.gather_nd(labels, idx_non_zero)\n  zeros = tf.zeros_like(image)\n\n  for CLS in tf.range(config['NUM_classes']):\n    idx_CLS = tf.where(tf.cast(labels, tf.int32) == CLS)\n    b = tf.gather_nd(boxes, idx_CLS).numpy()\n    for i in tf.range(b.shape[0]):\n      start, end = b[i, :2], b[i, 2:]\n      mask = tf.cast(cv.rectangle(zeros.numpy(), start, end , col[CLS], 2), tf.uint8)\n      image = tf.maximum(image * tf.cast((mask == 0), tf.uint8), mask)\n  return image\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, j in enumerate(Dataset_Test):\n  image = j[0]\n  true_ = j[1][0]\n  true = j[1][0][0]\n  if i == 1: break\nimage_ = tf.image.flip_left_right(image[0])\nimage_ = tfa.image.translate_xy(image_, [-120., 129.], replace=0.)\npred = model_test.predict(image_[tf.newaxis, ...])\nPlot_Bbox_NMS(image_, pred[0][0], pred[1][0], pred[2][0])\n\npred = model_test.predict(image[0][tf.newaxis, ...])\n#Plot_Bbox_NMS(image[0][tf.newaxis, ...], pred[0][0], pred[1][0], pred[2][0])\n#Plot_Bbox(image[0], true)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}